{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - T-test\n",
    "\n",
    "In statistics, t-test is used to test if two data samples have a significant difference between their means. There are two types of t-test:\n",
    "\n",
    "* **Student's t-test** (a.k.a. independent or uncorrelated t-test). This type of t-test is to compare the samples of **two independent populations** (e.g. test scores of students in two different classes). `scipy` provides the [`ttest_ind`](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ttest_ind.html) method to conduct student's t-test.\n",
    "\n",
    "* **Paired t-test** (a.k.a. dependent or correlated t-test). This type of t-test is to compare the samples of **the same population** (e.g. scores of different tests of students in the same class). `scipy` provides the [`ttest_re`](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ttest_rel.html) method to conduct paired t-test.\n",
    "\n",
    "Both types of t-tests return a number which is called the **p-value**. If p-value is below 0.05, we can confidently declare the null-hypothesis is rejected and the difference is significant. If p-value is between 0.05 and 0.1, we may also declare the null-hypothesis is rejected but we are not highly confident. If p-value is above 0.1 we do not reject the null-hypothesis.\n",
    "\n",
    "Read more about the t-test in [this article](https://researchbasics.education.uconn.edu/t-test/) and [this Quora](https://www.quora.com/What-is-the-difference-between-a-paired-and-unpaired-t-test). Make sure you understand when to use which type of t-test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dataset\n",
    "\n",
    "In this challenge we will work on the Pokemon dataset you have used last week. The goal is to test whether different groups of pokemon (e.g. Legendary vs Normal, Generation 1 vs 2, single-type vs dual-type) have different stats (e.g. HP, Attack, Defense, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0       65       65     45           1      False  \n",
       "1       80       80     60           1      False  \n",
       "2      100      100     80           1      False  \n",
       "3      122      120     80           1      False  \n",
       "4       60       50     65           1      False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "\n",
    "pokemon = pd.read_csv('../../lab-df-calculation-and-transformation/your-code/Pokemon.csv')\n",
    "print(pokemon.shape)\n",
    "pokemon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we want to define a function with which we can test the means of a feature set of two samples. \n",
    "\n",
    "In the next cell you'll see the annotations of the Python function that explains what this function does and its arguments and returned value. This type of annotation is called **docstring** which is a convention used among Python developers. The docstring convention allows developers to write consistent tech documentations for their codes so that others can read. It also allows some websites to automatically parse the docstrings and display user-friendly documentations.\n",
    "\n",
    "Follow the specifications of the docstring and complete the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this case we will use the t test for independent samples, as the samples we'll compare are independent\n",
    "\n",
    "def t_test_features(s1, s2, features=['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Total']):\n",
    "    \"\"\"Test means of a feature set of two samples\n",
    "    \n",
    "    Args:\n",
    "        s1 (dataframe): sample 1\n",
    "        s2 (dataframe): sample 2\n",
    "        features (list): an array of features to test\n",
    "    \n",
    "    Returns:\n",
    "        dict: a dictionary of t-test scores for each feature where the feature name is the key and the p-value is the value\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Your code here\n",
    "    for f in features:\n",
    "        results[f] = stats.ttest_ind(s1[f],s2[f])[1]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the `t_test_features` function, conduct t-test for Lengendary vs non-Legendary pokemons.\n",
    "\n",
    "*Hint: your output should look like below:*\n",
    "\n",
    "```\n",
    "{'HP': 1.0026911708035284e-13,\n",
    " 'Attack': 2.520372449236646e-16,\n",
    " 'Defense': 4.8269984949193316e-11,\n",
    " 'Sp. Atk': 1.5514614112239812e-21,\n",
    " 'Sp. Def': 2.2949327864052826e-15,\n",
    " 'Speed': 1.049016311882451e-18,\n",
    " 'Total': 9.357954335957446e-47}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HP': 3.330647684846191e-15,\n",
       " 'Attack': 7.827253003205333e-24,\n",
       " 'Defense': 1.5842226094427255e-12,\n",
       " 'Sp. Atk': 6.314915770427266e-41,\n",
       " 'Sp. Def': 1.8439809580409333e-26,\n",
       " 'Speed': 2.3540754436897763e-21,\n",
       " 'Total': 3.0952457469652825e-52}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "legendary = pokemon[pokemon.Legendary==True]\n",
    "normal = pokemon[pokemon.Legendary==False]\n",
    "\n",
    "r = t_test_features(legendary, normal)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the test results above, what conclusion can you make? Do Legendary and non-Legendary pokemons have significantly different stats on each feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can reject h0 at 5% significance level, so we accept the mean of HP is different for legendary and normal pokemons\n",
      "\n",
      "We can reject h0 at 5% significance level, so we accept the mean of Attack is different for legendary and normal pokemons\n",
      "\n",
      "We can reject h0 at 5% significance level, so we accept the mean of Defense is different for legendary and normal pokemons\n",
      "\n",
      "We can reject h0 at 5% significance level, so we accept the mean of Sp. Atk is different for legendary and normal pokemons\n",
      "\n",
      "We can reject h0 at 5% significance level, so we accept the mean of Sp. Def is different for legendary and normal pokemons\n",
      "\n",
      "We can reject h0 at 5% significance level, so we accept the mean of Speed is different for legendary and normal pokemons\n",
      "\n",
      "We can reject h0 at 5% significance level, so we accept the mean of Total is different for legendary and normal pokemons\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your comment here\n",
    "#h0: the mean for f in feature is equal for legendary and normal pokemons\n",
    "\n",
    "for e,i in r.items():\n",
    "    if i < 0.05:\n",
    "        print(f\"We can reject h0 at 5% significance level, so we accept the mean of {e} is different for legendary and normal pokemons\\n\")\n",
    "    elif 0.1 > i > 0.05:\n",
    "        print(f\"We can reject h0 and say the mean of {e} is diff for both type of pokemon. However is possible we'll have a Type I Error (reject h0 when True)\\n\")\n",
    "    else:\n",
    "        print(f\"We cannot reject h0, so {e} is equal for both types of pokemon\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, conduct t-test for Generation 1 and Generation 2 pokemons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HP': 0.13791881412813622,\n",
       " 'Attack': 0.24050968418101457,\n",
       " 'Defense': 0.5407630349194362,\n",
       " 'Sp. Atk': 0.141197881763315,\n",
       " 'Sp. Def': 0.16781226231606386,\n",
       " 'Speed': 0.0028356954812578704,\n",
       " 'Total': 0.559914064901444}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "g1 = pokemon[pokemon.Generation==1]\n",
    "g2 = pokemon[pokemon.Generation==2]\n",
    "\n",
    "r1 = t_test_features(g1, g2)\n",
    "r1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What conclusions can you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We cannot reject h0, so HP is equal for both types of pokemon\n",
      "\n",
      "We cannot reject h0, so Attack is equal for both types of pokemon\n",
      "\n",
      "We cannot reject h0, so Defense is equal for both types of pokemon\n",
      "\n",
      "We cannot reject h0, so Sp. Atk is equal for both types of pokemon\n",
      "\n",
      "We cannot reject h0, so Sp. Def is equal for both types of pokemon\n",
      "\n",
      "We can reject h0 at 5% significance level, so we accept the mean of Speed is different for generation1 and generation2 pokemons\n",
      "\n",
      "We cannot reject h0, so Total is equal for both types of pokemon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your comment here\n",
    "\n",
    "#h0: the mean for f in feature is equal for g1 and g2 pokemons\n",
    "\n",
    "for e,i in r1.items():\n",
    "    if i < 0.05:\n",
    "        print(f\"We can reject h0 at 5% significance level, so we accept the mean of {e} is different for generation1 and generation2 pokemons\\n\")\n",
    "    elif 0.1 > i > 0.05:\n",
    "        print(f\"We can reject h0 and say the mean of {e} is diff for both type of pokemon. However is possible we'll have a Type I Error (reject h0 when True)\\n\")\n",
    "    else:\n",
    "        print(f\"We cannot reject h0, so {e} is equal for both types of pokemon\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare pokemons who have single type vs those having two types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HP': 0.11060643144431853,\n",
       " 'Attack': 0.00015741395666164396,\n",
       " 'Defense': 3.250594205757004e-08,\n",
       " 'Sp. Atk': 0.0001454917404035147,\n",
       " 'Sp. Def': 0.00010893304795534396,\n",
       " 'Speed': 0.024051410794037463,\n",
       " 'Total': 1.1749035008828668e-07}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "pok1Type = pokemon[pokemon[\"Type 2\"].isnull()]\n",
    "pok2Type = pokemon[pokemon[\"Type 2\"].notna()]\n",
    "\n",
    "r2 = t_test_features(pok1Type, pok2Type)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What conclusions can you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We cannot reject h0, so HP is equal for both types of pokemon\n",
      "\n",
      "We can reject h0 at 5% significance level, so we accept the mean of Attack is different for 1type and 2types pokemons\n",
      "\n",
      "We can reject h0 at 5% significance level, so we accept the mean of Defense is different for 1type and 2types pokemons\n",
      "\n",
      "We can reject h0 at 5% significance level, so we accept the mean of Sp. Atk is different for 1type and 2types pokemons\n",
      "\n",
      "We can reject h0 at 5% significance level, so we accept the mean of Sp. Def is different for 1type and 2types pokemons\n",
      "\n",
      "We can reject h0 at 5% significance level, so we accept the mean of Speed is different for 1type and 2types pokemons\n",
      "\n",
      "We can reject h0 at 5% significance level, so we accept the mean of Total is different for 1type and 2types pokemons\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your comment here\n",
    "\n",
    "#h0: the mean for f in feature is equal for pok1Type and pok2Type pokemons\n",
    "\n",
    "for e,i in r2.items():\n",
    "    if i < 0.05:\n",
    "        print(f\"We can reject h0 at 5% significance level, so we accept the mean of {e} is different for 1type and 2types pokemons\\n\")\n",
    "    elif 0.1 > i > 0.05:\n",
    "        print(f\"We can reject h0 and say the mean of {e} is diff for both type of pokemon. However is possible we'll have a Type I Error (reject h0 when True)\\n\")\n",
    "    else:\n",
    "        print(f\"We cannot reject h0, so {e} is equal for both types of pokemon\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we want to compare whether there are significant differences of `Attack` vs `Defense`  and  `Sp. Atk` vs `Sp. Def` of all pokemons. Please write your code below.\n",
    "\n",
    "*Hint: are you comparing different populations or the same population?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=4.325566393330478, pvalue=1.7140303479358558e-05) \n",
      "\n",
      " Ttest_relResult(statistic=0.853986188453353, pvalue=0.3933685997548122)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "#now we will implement the t test for related samples\n",
    "\n",
    "#h0: the mean of the compared sample is equal\n",
    "\n",
    "attack_defense = stats.ttest_rel(pokemon.Attack,pokemon.Defense)\n",
    "spAtk_spDef = stats.ttest_rel(pokemon[\"Sp. Atk\"],pokemon[\"Sp. Def\"])\n",
    "print(attack_defense,\"\\n\\n\",spAtk_spDef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What conclusions can you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 5% confindence level,we reject h0 and we can say Attack and Defense have diff means\n",
      "we cannot reject h0\n"
     ]
    }
   ],
   "source": [
    "# Your comment here\n",
    "if attack_defense[1] < 0.05:\n",
    "    print(\"with 5% confindence level,we reject h0 and we can say Attack and Defense have diff means\")\n",
    "elif 0.1 < attack_defense[1] < 0.05:\n",
    "    print(\"with 10% confindence level,we reject h0 but we could have a Type I Error\")\n",
    "else:\n",
    "    print(\"we cannot reject h0\")\n",
    "    \n",
    "if spAtk_spDef[1] < 0.05:\n",
    "    print(\"with 5% confindence level,we reject h0 and we can say Sp Atk and Sp Def have diff means\")\n",
    "elif 0.1 < spAtk_spDef[1] < 0.05:\n",
    "    print(\"with 10% confindence level,we reject h0 but we could have a Type I Error\")\n",
    "else:\n",
    "    print(\"we cannot reject h0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
